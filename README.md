# perceptron

Функция train — обучает, predict — обрабатывает входные данные уже обученными синапсами и выдает ответ, trainmass — запускает обучение по всем входным данным(2 — это количество выходных данных, 4 — количество данных в примере, 1 — это лерн рейт, 60000 — количество циклов обучения), create — создает массив случайных синапсов для обучения.

В этом примере массив X имеет 4 набора данных и массив y 4 набора выходных данных.

После запуска имеем вывод:

[0.4835439912709079, 0.5593653075469635]
[0.8848108739666853, 0.9682956213528969]

Первый массив — это ответ на входные данные X[0] — [0.1, 0.2, 0.3, 0.4].
Второй массив — это ответ на данные которые не были в обучающей выборке [0.5, 0.6, 0.7, 0.8].

Как видите персептрон продолжил числовой ряд почти верно с небольшими отклонениями.
Немного разберем принцип его работы. Персептрон получает что-то похожее на систему линейных уравнений:

0.1*x1 + 0.2*x2 + 0.3*x3 + 0.4*x4 = 0.5
0.2*x1 + 0.3*x2 + 0.4*x3 + 0.5*x4 = 0.6
0.4*x1 + 0.5*x2 + 0.6*x3 + 0.7*x4 = 0.8
0.5*x1 + 0.6*x2 + 0.7*x3 + 0.8*x4 = 0.9

И методом обратного распространения ошибки находит соответствующие x1, x2, x3, x4.
Для второго выходного значения создаются другие y1, y2, y3, y4.

Однослойный персептрон может решать только линейные задачи. Для нелинейности нужно добавить еще слой или несколько слоев.
